{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzA0EkFaORio",
        "outputId": "31709cb6-ede4-432b-dd17-0698e2e45f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# #Change the current working directory to the path of Google Cloud Drive\n",
        "# path=\"/content/drive/My Drive/Colab Notebooks/\"\n",
        "# os.chdir(path)\n",
        "# os.listdir(path)\n",
        "# #Use the wget command to download the dataset to this path\n",
        "# !wget https://fordatis.fraunhofer.de/bitstream/fordatis/151.2/1/fraunhofer_eas_dataset_for_unbalance_detection_v1.zip"
      ],
      "metadata": {
        "id": "JtJsInPSOimK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKHvpuF8XRNm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy as sc\n",
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.colors import LogNorm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#url='https://fordatis.fraunhofer.de/bitstream/fordatis/151.2/1/fraunhofer_eas_dataset_for_unbalance_detection_v1.zip'"
      ],
      "metadata": {
        "id": "nA-e4cFAFb3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip gdrive/My\\ Drive/Colab\\ Notebooks/data/fraunhofer_eas_dataset_for_unbalance_detection_v1.zip"
      ],
      "metadata": {
        "id": "LdMG1VYOVthN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url='/content/drive/MyDrive/Colab Notebooks/fraunhofer_eas_dataset_for_unbalance_detection_v1.zip'\n",
        "use_reference_models = True\n",
        "model_path = '/content/drive/MyDrive/References_cnn'"
      ],
      "metadata": {
        "id": "bpiknEvoFg8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(url, 'r') as f:\n",
        "    with f.open('0D.csv', 'r') as c:\n",
        "        data0D = pd.read_csv(c)\n",
        "    with f.open('0E.csv', 'r') as c:\n",
        "        data0E = pd.read_csv(c)\n",
        "    with f.open('1D.csv', 'r') as c:\n",
        "        data1D = pd.read_csv(c)\n",
        "    with f.open('1E.csv', 'r') as c:\n",
        "        data1E = pd.read_csv(c)\n",
        "    with f.open('2D.csv', 'r') as c:\n",
        "        data2D = pd.read_csv(c)\n",
        "    with f.open('2E.csv', 'r') as c:\n",
        "        data2E = pd.read_csv(c)\n",
        "    with f.open('3D.csv', 'r') as c:\n",
        "        data3D = pd.read_csv(c)\n",
        "    with f.open('3E.csv', 'r') as c:\n",
        "        data3E = pd.read_csv(c)\n",
        "    with f.open('4D.csv', 'r') as c:\n",
        "        data4D = pd.read_csv(c)\n",
        "    with f.open('4E.csv', 'r') as c:\n",
        "        data4E = pd.read_csv(c)"
      ],
      "metadata": {
        "id": "Usx_Wzg1FnK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skip = 50000\n",
        "data0D = data0D.iloc[skip:,:]\n",
        "data1D = data1D.iloc[skip:,:]\n",
        "data2D = data2D.iloc[skip:,:]\n",
        "data3D = data3D.iloc[skip:,:]\n",
        "data4D = data4D.iloc[skip:,:]\n",
        "\n",
        "data0E = data0E.iloc[skip:,:]\n",
        "data1E = data1E.iloc[skip:,:]\n",
        "data2E = data2E.iloc[skip:,:]\n",
        "data3E = data3E.iloc[skip:,:]\n",
        "data4E = data4E.iloc[skip:,:]"
      ],
      "metadata": {
        "id": "AnopsobKGfWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {'no_unbalance':0, 'unbalance':1}\n",
        "sensor = 'Vibration_1'\n",
        "samples_per_second = 4096\n",
        "seconds_per_analysis = 1.0\n",
        "window = int(samples_per_second*seconds_per_analysis)\n",
        "\n",
        "def get_features(data, label):\n",
        "    n = int(np.floor(len(data)/window))\n",
        "    data = data[:int(n)*window]\n",
        "    X = data.values.reshape((n, window))\n",
        "    y = np.ones(n)*labels[label]\n",
        "    return X,y\n",
        "\n",
        "X0,y0 = get_features(data0D[sensor], \"no_unbalance\")\n",
        "X1,y1 = get_features(data1D[sensor], \"unbalance\")\n",
        "X2,y2 = get_features(data2D[sensor], \"unbalance\")\n",
        "X3,y3 = get_features(data3D[sensor], \"unbalance\")\n",
        "X4,y4 = get_features(data4D[sensor], \"unbalance\")\n",
        "X=np.concatenate([X0, X1, X2, X3, X4])\n",
        "y=np.concatenate([y0, y1, y2, y3, y4])\n",
        "\n",
        "X0_val, y0_val = get_features(data0E[sensor], \"no_unbalance\")\n",
        "X1_val, y1_val = get_features(data1E[sensor], \"unbalance\")\n",
        "X2_val, y2_val = get_features(data2E[sensor], \"unbalance\")\n",
        "X3_val, y3_val = get_features(data3E[sensor], \"unbalance\")\n",
        "X4_val, y4_val = get_features(data4E[sensor], \"unbalance\")\n",
        "X_val=np.concatenate([X0_val, X1_val, X2_val, X3_val, X4_val])\n",
        "y_val=np.concatenate([y0_val, y1_val, y2_val, y3_val, y4_val])"
      ],
      "metadata": {
        "id": "6TJ0et_cY6wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2HtcgHyziAl",
        "outputId": "74d95073-1c69-4c20-c394-70b459274cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.1606684e-02  2.2007227e-02  2.1793842e-02 ...  1.6417503e-02\n",
            "   1.6212463e-02  1.5910864e-02]\n",
            " [ 1.6222000e-02  1.5923977e-02  1.6121864e-02 ...  1.2435913e-02\n",
            "   1.2710094e-02  1.2711287e-02]\n",
            " [ 1.2282133e-02  1.2310743e-02  1.2122393e-02 ...  9.3388557e-03\n",
            "   9.8717213e-03  9.6476078e-03]\n",
            " ...\n",
            " [ 1.1742115e-03  1.1193752e-03  1.2993813e-03 ...  8.2612038e-04\n",
            "   4.1604042e-04  8.5115433e-04]\n",
            " [ 6.6399574e-04  4.4107437e-05 -1.9907951e-04 ...  3.7312508e-04\n",
            "   9.3460083e-04  1.1575222e-03]\n",
            " [ 8.2135201e-04  9.4175339e-04  6.2346458e-04 ...  1.1920929e-03\n",
            "   6.9975853e-04  5.7458878e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, y.shape, X_val.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86lysvEfY-3Z",
        "outputId": "70c89b08-c6ce-4d49-dce5-ca6e34a3847c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32166, 4096) (32166,) (8359, 4096) (8359,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_test_ratio = 0.9\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 1-train_test_ratio, random_state = 0)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))"
      ],
      "metadata": {
        "id": "Ewv8IyL4ZEHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk7NojlLZIq5",
        "outputId": "cb65dff5-9f1c-4fb1-f197-f33bd8a249fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28949, 4096, 1) (28949,) (3217, 4096, 1) (3217,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import BatchNormalization,LeakyReLU,Dense,Dropout\n",
        "from keras.layers import Input,Conv1D,MaxPooling1D,Flatten,ReLU\n",
        "from keras.models import Sequential, load_model, Model"
      ],
      "metadata": {
        "id": "-UiVgZKzi7gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.regularizers import l1_l2\n",
        "\n",
        "weight_for_0 = len(y)/(2*len(y[y==0]))\n",
        "weight_for_1 = len(y)/(2*len(y[y==1]))\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "def train_models(n_conv_layers):\n",
        "    #n_conv_layers = 3 # [1,2,3,4]\n",
        "    n_dense_units = 128\n",
        "    dropout_rate = 0.0\n",
        "    use_batch_normalization = True # [True, False]\n",
        "    filter_size = 9 # [5,7,9]\n",
        "    learning_rate = 0.0001\n",
        "    n_epochs = 100 # [50,100,200]\n",
        "\n",
        "    X_in = Input(shape=(X_train.shape[1],1))\n",
        "    x = X_in\n",
        "    for j in range(n_conv_layers):\n",
        "        print(j)\n",
        "        x = Conv1D(filters=(j+1)*10,\n",
        "                   kernel_size=filter_size,\n",
        "                   strides=1,\n",
        "                   activation='linear',\n",
        "                   kernel_initializer='he_uniform')(x)\n",
        "        if use_batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.05)(x)\n",
        "        x = MaxPooling1D(pool_size=5, strides=2)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units = n_dense_units, activation='linear')(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Dropout(rate=dropout_rate)(x)\n",
        "    X_out = Dense(units = 1, activation = 'sigmoid')(x)\n",
        "    classifier = Model(X_in, X_out)\n",
        "    classifier.summary()\n",
        "\n",
        "    best_model_filepath = f\"{model_path}/cnn_{n_conv_layers}_layers.h5\"\n",
        "    checkpoint = ModelCheckpoint(best_model_filepath, monitor='val_loss',\n",
        "                                 verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "    classifier.compile(optimizer = Adam(lr=learning_rate), loss = 'binary_crossentropy',\n",
        "                       metrics = ['accuracy'])\n",
        "\n",
        "    classifier.fit(X_train, y_train, epochs = n_epochs, batch_size = 64,\n",
        "                   validation_data=(X_test, y_test), callbacks=[checkpoint],\n",
        "                   class_weight=class_weight)\n",
        "    classifier = load_model(best_model_filepath)\n",
        "    score = classifier.evaluate(X_val, y_val)"
      ],
      "metadata": {
        "id": "nLXuheYKZMZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not True:\n",
        "    for i in range(1,5):\n",
        "        train_models(i)"
      ],
      "metadata": {
        "id": "hQ-70cK1ZW9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_1 = X_val[:len(y0_val),:,:]\n",
        "X_val_2 = X_val[len(y0_val):len(y0_val)+len(y1_val),:,:]\n",
        "X_val_3 = X_val[len(y0_val)+len(y1_val):len(y0_val)+len(y1_val)+\n",
        "                len(y2_val),:,:]\n",
        "X_val_4 = X_val[len(y0_val)+len(y1_val)+len(y2_val):len(y0_val)+\n",
        "                len(y1_val)+len(y2_val)+len(y3_val),:,:]\n",
        "X_val_5 = X_val[len(y0_val)+len(y1_val)+len(y2_val)+len(y3_val):len(y0_val)+\n",
        "                len(y1_val)+len(y2_val)+len(y3_val)+len(y4_val),:,:]"
      ],
      "metadata": {
        "id": "IUmi3QGPZZeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiClv7cE31fP",
        "outputId": "c6575e13-217c-4e42-ee55-4373d17c5b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []\n",
        "accuracies_all = []\n",
        "for layer_n in range(1,5):\n",
        "\n",
        "    filepath = f\"{model_path}/cnn_{layer_n}_layers.h5\"\n",
        "    model_i = load_model(filepath)\n",
        "\n",
        "    val_acc_1 = model_i.evaluate(X_val_1, y0_val)[1]\n",
        "    val_acc_2 = model_i.evaluate(X_val_2, y1_val)[1]\n",
        "    val_acc_3 = model_i.evaluate(X_val_3, y2_val)[1]\n",
        "    val_acc_4 = model_i.evaluate(X_val_4, y3_val)[1]\n",
        "    val_acc_5 = model_i.evaluate(X_val_5, y4_val)[1]\n",
        "    val_acc_all = model_i.evaluate(X_val, y_val)[1]\n",
        "    accuracies_layer_i = [val_acc_1, val_acc_2, val_acc_3, val_acc_4, val_acc_5]\n",
        "    accuracies.append(accuracies_layer_i)\n",
        "    accuracies_all.append(val_acc_all)\n",
        "\n",
        "accuracies = np.array(accuracies)\n",
        "accuracies_all = np.array(accuracies_all)"
      ],
      "metadata": {
        "id": "yFqCyO3tZrTe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "6f4b7a73-d833-4a28-e515-a288fdb39319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5bbf4eaec141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{model_path}/cnn_{layer_n}_layers.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mval_acc_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at /content/drive/MyDrive/References_cnn/cnn_1_layers.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies_all"
      ],
      "metadata": {
        "id": "Epxavd4i1t6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(12,8))\n",
        "ax1=plt.subplot(111, title = \"Unbalance Classification Trained with all Unbalances\")\n",
        "unbalances = np.array([0, 4.59e-5, 6.07e-5,7.55e-5,1.521e-4])\n",
        "ax1.plot(1e6*unbalances, accuracies[0,:], label=f\"1 layer, accuracy: {100.0*accuracies_all[0]:.1f}%\", marker=\"+\", ls=\"--\")\n",
        "ax1.plot(1e6*unbalances, accuracies[1,:], label=f\"2 layers, accuracy: {100.0*accuracies_all[1]:.1f}%\", marker=\"+\", ls=\"--\")\n",
        "ax1.plot(1e6*unbalances, accuracies[2,:], label=f\"3 layers, accuracy: {100.0*accuracies_all[2]:.1f}%\", marker=\"+\", ls=\"--\")\n",
        "ax1.plot(1e6*unbalances, accuracies[3,:], label=f\"4 layers, accuracy: {100.0*accuracies_all[3]:.1f}%\", marker=\"+\", ls=\"--\")\n",
        "plt.ylabel(\"Accuracy on Evaluation Dataset\")\n",
        "plt.xlabel(\"Unbalance Factor [mm g]\")\n",
        "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
        "plt.ylim([0.45, 1.05])\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ave340iav7-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model1 = load_model(f\"{model_path}/cnn_1_layers.h5\")\n",
        "model2 = load_model(f\"{model_path}/cnn_2_layers.h5\")\n",
        "model3 = load_model(f\"{model_path}/cnn_3_layers.h5\")\n",
        "model4 = load_model(f\"{model_path}/cnn_4_layers.h5\")"
      ],
      "metadata": {
        "id": "Z47SGpFOv-sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def v2rpm(v):\n",
        "    return 212*v + 209\n",
        "\n",
        "from scipy.stats import mode\n",
        "# 3s ramp up\n",
        "fade_in = np.arange(0.0, 4.0, 4.0/(3*4096))\n",
        "# complete voltage sweep\n",
        "measurement_cycle = np.repeat(np.arange(4.0, 8.2, 0.1), 4096*20.0)\n",
        "# measurement: start-up + 2 voltage sweeps\n",
        "measurement = np.concatenate([fade_in, np.tile(measurement_cycle,3)])\n",
        "# select the data as actually used\n",
        "measurement1 = measurement[50000:]\n",
        "measurement1 = measurement1[:int(len(measurement1)/4096)*4096].reshape(-1,4096)\n",
        "voltages_measurement = mode(measurement1, axis=1)[0]\n",
        "voltages_used = np.concatenate([voltages_measurement[:len(X_val_1)],\n",
        "                                voltages_measurement[:len(X_val_2)],\n",
        "                                voltages_measurement[:len(X_val_3)],\n",
        "                                voltages_measurement[:len(X_val_4)],\n",
        "                                voltages_measurement[:len(X_val_5)]])\n",
        "rpms_used = v2rpm(voltages_used)"
      ],
      "metadata": {
        "id": "p6rfIT0fwCEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rpm_borders = np.arange(1050, 1975, 25)\n",
        "errors_per_rpm_range1 = []\n",
        "errors_per_rpm_range2 = []\n",
        "errors_per_rpm_range3 = []\n",
        "errors_per_rpm_range4 = []\n",
        "for i in range(len(rpm_borders)-1):\n",
        "    eval_inds = np.where((rpms_used>rpm_borders[i])&(rpms_used<rpm_borders[i+1]))[0]\n",
        "    errors_per_rpm_range1.append(\n",
        "        1-np.mean(np.abs(np.int32(model1.predict(X_val[eval_inds])>0.5).reshape(-1)-y_val[eval_inds])))\n",
        "    errors_per_rpm_range2.append(\n",
        "        1-np.mean(np.abs(np.int32(model2.predict(X_val[eval_inds])>0.5).reshape(-1)-y_val[eval_inds])))\n",
        "    errors_per_rpm_range3.append(\n",
        "        1-np.mean(np.abs(np.int32(model3.predict(X_val[eval_inds])>0.5).reshape(-1)-y_val[eval_inds])))\n",
        "    errors_per_rpm_range4.append(\n",
        "        1-np.mean(np.abs(np.int32(model4.predict(X_val[eval_inds])>0.5).reshape(-1)-y_val[eval_inds])))"
      ],
      "metadata": {
        "id": "qhoGvcUwwFfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(12,8))\n",
        "ax1=plt.subplot(111, title = \"Rotation Speed Dependent Evaluation\")\n",
        "ax1.plot(np.array(rpm_borders[:-1])+25, errors_per_rpm_range1, marker=\"+\", ls=\"--\", label=\"1 conv. layer\")\n",
        "ax1.plot(np.array(rpm_borders[:-1])+25, errors_per_rpm_range2, marker=\"+\", ls=\"--\", label=\"2 conv. layers\")\n",
        "ax1.plot(np.array(rpm_borders[:-1])+25, errors_per_rpm_range3, marker=\"+\", ls=\"--\", label=\"3 conv. layers\")\n",
        "ax1.plot(np.array(rpm_borders[:-1])+25, errors_per_rpm_range4, marker=\"+\", ls=\"--\", label=\"4 conv. layers\")\n",
        "plt.ylabel(\"Accuracy on Evaluation Dataset\")\n",
        "plt.xlabel(\"Rotation Speed [rpm]\")\n",
        "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
        "plt.ylim([0.45, 1.05])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CNAboUPdwHmQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
